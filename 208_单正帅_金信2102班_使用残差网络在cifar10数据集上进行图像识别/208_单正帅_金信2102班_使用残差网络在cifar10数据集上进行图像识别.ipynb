{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h2 style='color:blue' align='center'>使用残差网络在cifar10数据集上进行图像识别</h2>"]},{"cell_type":"code","execution_count":104,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T01:51:26.221803Z","iopub.status.busy":"2023-12-14T01:51:26.221047Z","iopub.status.idle":"2023-12-14T01:51:26.229526Z","shell.execute_reply":"2023-12-14T01:51:26.228561Z","shell.execute_reply.started":"2023-12-14T01:51:26.221760Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import time\n","import os\n","import ssl\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","Epochs=20"]},{"cell_type":"markdown","metadata":{},"source":["![avatar](small_images.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["CIFAR-10数据集是一个用于监督学习训练的数据集，由60000个样本组成，每个样本都是一张32*32像素的RGB图像，共有10个类别，分别是飞机（airplane）、汽车（automobile）、鸟（bird）、猫（cat）、鹿（deer）、狗（dog）、青蛙（frog）、马（horse）、船（ship）和卡车（truck）。\n","以下是CIFAR-10数据集的出处链接：\n","[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/cifar10)"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T01:51:26.231559Z","iopub.status.busy":"2023-12-14T01:51:26.231254Z","iopub.status.idle":"2023-12-14T01:51:26.241430Z","shell.execute_reply":"2023-12-14T01:51:26.240479Z","shell.execute_reply.started":"2023-12-14T01:51:26.231525Z"},"trusted":true},"outputs":[],"source":["#数据预处理\n","transform = transforms.Compose(\n","    [\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomGrayscale(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","transform1 = transforms.Compose(\n","    [\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"]},{"cell_type":"code","execution_count":106,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T01:51:26.242938Z","iopub.status.busy":"2023-12-14T01:51:26.242617Z","iopub.status.idle":"2023-12-14T01:51:27.842109Z","shell.execute_reply":"2023-12-14T01:51:27.841174Z","shell.execute_reply.started":"2023-12-14T01:51:26.242912Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["# 数据集根目录\n","data_root = '/kaggle/input/cifar-10-batches-py-tar-gz/'\n","\n","# 训练集\n","trainset = torchvision.datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n","\n","# 测试集\n","testset = torchvision.datasets.CIFAR10(root=data_root, train=False, download=True, transform=transform1)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=50, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"markdown","metadata":{},"source":["# 残差网络"]},{"cell_type":"code","execution_count":107,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T01:51:27.845159Z","iopub.status.busy":"2023-12-14T01:51:27.844518Z","iopub.status.idle":"2023-12-14T01:51:27.855298Z","shell.execute_reply":"2023-12-14T01:51:27.854358Z","shell.execute_reply.started":"2023-12-14T01:51:27.845099Z"},"trusted":true},"outputs":[],"source":["# 定义带两个卷积路径和一条捷径的残差基本块类\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):  # 初始化函数，in_planes为输入通道数，planes为输出通道数，步长默认为1\n","        super(BasicBlock, self).__init__()\n","        # 定义第一个卷积，默认卷积前后图像大小不变但可修改stride使其变化，通道可能改变\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        # 定义第一个批归一化\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        # 定义第二个卷积，卷积前后图像大小不变，通道数不变\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        # 定义第二个批归一化\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        # 定义一条捷径，若两个卷积前后的图像尺寸有变化(stride不为1导致图像大小变化或通道数改变)\n","        # 捷径通过1×1卷积用stride修改大小以及用expansion修改通道数，以便于捷径输出和两个卷积的输出尺寸匹配相加\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion * planes)\n","            )\n","\n","    # 定义前向传播函数，输入图像为x，输出图像为out\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))  # 第一个卷积和第一个批归一化后用ReLU函数激活\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)  # 第二个卷积和第二个批归一化后与捷径相加\n","        out = F.relu(out)  # 两个卷积路径输出与捷径输出相加后用ReLU激活\n","        return out\n"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T01:51:27.857316Z","iopub.status.busy":"2023-12-14T01:51:27.857011Z","iopub.status.idle":"2023-12-14T01:51:27.871221Z","shell.execute_reply":"2023-12-14T01:51:27.869764Z","shell.execute_reply.started":"2023-12-14T01:51:27.857281Z"},"trusted":true},"outputs":[],"source":["# 定义残差网络ResNet18\n","class ResNet(nn.Module):\n","    # 定义初始函数，输入参数为残差块，残差块数量，默认参数为分类数10\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","# 设置第一层的输入通道数\n","        self.in_planes = 64\n","# 定义输入图片先进行一次卷积与批归一化，使图像大小不变，通道数由3变为64得两个操作\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","# 定义第一层，输入通道数64，有num_blocks[0]个残差块，残差块中第一个卷积步长自定义为1\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","# 定义第二层，输入通道数128，有num_blocks[1]个残差块，残差块中第一个卷积步长自定义为2\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","# 定义第三层，输入通道数256，有num_blocks[2]个残差块，残差块中第一个卷积步长自定义为2\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","# 定义第四层，输入通道数512，有num_blocks[3]个残差块，残差块中第一个卷积步长自定义为2\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","# 定义全连接层，输入512*block.expansion个神经元，输出10个分类神经元\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","# 定义创造层的函数，在同一层中通道数相同，输入参数为残差块，通道数，残差块数量，步长\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        # strides列表第一个元素stride表示第一个残差块第一个卷积步长，其余元素表示其他残差块第一个卷积步长为1\n","        strides = [stride] + [1]*(num_blocks-1)\n","# 创建一个空列表用于放置层\n","        layers = []\n","# 遍历strides列表，对本层不同的残差块设置不同的stride\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))  # 创建残差块添加进本层\n","            self.in_planes = planes * block.expansion  # 更新本层下一个残差块的输入通道数或本层遍历结束后作为下一层的输入通道数\n","        return nn.Sequential(*layers)  # 返回层列表\n","# 定义前向传播函数，输入图像为x，输出预测数据\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))  # 第一个卷积和第一个批归一化后用ReLU函数激活\n","        out = self.layer1(out)  # 第一层传播\n","        out = self.layer2(out)  # 第二层传播\n","        out = self.layer3(out)  # 第三层传播\n","        out = self.layer4(out)  # 第四层传播\n","        out = F.avg_pool2d(out, 4)  # 经过一次4×4的平均池化\n","        out = out.view(out.size(0), -1)  # 将数据flatten平坦化\n","        out = self.linear(out)  # 全连接传播\n","        return out\n"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T01:51:27.873430Z","iopub.status.busy":"2023-12-14T01:51:27.873046Z","iopub.status.idle":"2023-12-14T01:51:27.887474Z","shell.execute_reply":"2023-12-14T01:51:27.886651Z","shell.execute_reply.started":"2023-12-14T01:51:27.873393Z"},"trusted":true},"outputs":[],"source":["# 定义准确度评估函数(参数为数据装载器，网络模型，运算设备)\n","def evaluate_accuracy(data_iter, net, device=None):\n","    # 如果没指定device就使用net的device\n","    if device is None and isinstance(net, torch.nn.Module):\n","        device = list(net.parameters())[0].device\n","    # 累计正确样本设为0.0，累计预测样本数设为0\n","    acc_sum, n = 0.0, 0\n","    # 准确度评估阶段，with torch.no_grad()封装内关闭梯度计算功能\n","    with torch.no_grad():\n","        # 从数据加载器上批量读取数据X与标签y\n","        for X, y in data_iter:\n","            if isinstance(net, torch.nn.Module):  # 若网络模型继承自torch.nn.Module\n","                net.eval()  # 进入评估模式, 这会关闭dropout，以CPU进行准确度累加计算\n","                # 判断net(X.to(device)).argmax(dim=1)即X经net后输出的批量预测列表中每一个样本输出的最大值和y.to(device)此样本真实标签是否相同，\n","                # 若相同则表示预测正确，等号表达式为True，值为1；否则表达式为False，值为0。将批量所有样本的等号表达式值求和后再加给acc_sum\n","                # 每一次acc_sum增加一批量中预测正确的样本个数，随着不断的遍历，acc_sum表示累计的所有预测正确的样本个数\n","                acc_sum += (net(X.to(device)).argmax(dim=1) ==\n","                            y.to(device)).float().sum().cpu().item()\n","                net.train()  # 改回训练模式\n","            else:  # 若使用自定义的模型\n","                # 查看net对象中是否有变量名为is_training的参数，若有将is_training设置成False后遍历累加每一批量中的预测正确的样本数量\n","                if ('is_training' in net.__code__.co_varnames):\n","                    acc_sum += (net(X, is_training=False).argmax(dim=1)\n","                                == y).float().sum().item()\n","                # 若net对象中没有变量名为is_training的参数，则遍历累加每一批量中的预测正确的样本数量\n","                else:\n","                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n","            # 每一次y.shape[0]表示一批量中标签个数，也就是样本个数。所以n表示累计的所有预测过的样本个数，无论正确与否\n","            n += y.shape[0]\n","    return acc_sum / n  # 用累计的所有预测正确的样本个数除以累计的所有预测过的样本个数得到准确率\n"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T01:51:27.888901Z","iopub.status.busy":"2023-12-14T01:51:27.888646Z","iopub.status.idle":"2023-12-14T01:51:27.899411Z","shell.execute_reply":"2023-12-14T01:51:27.898665Z","shell.execute_reply.started":"2023-12-14T01:51:27.888878Z"},"trusted":true},"outputs":[],"source":["def classify(net, device):\n","    class_correct = list(0. for i in range(10))\n","    class_total = list(0. for i in range(10))\n","    for data in testloader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(4):\n","            label = labels[i]\n","            class_correct[label] += c[i]\n","            class_total[label] += 1\n","\n","    for i in range(10):\n","        print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T01:51:27.901087Z","iopub.status.busy":"2023-12-14T01:51:27.900742Z","iopub.status.idle":"2023-12-14T01:51:27.912252Z","shell.execute_reply":"2023-12-14T01:51:27.911458Z","shell.execute_reply.started":"2023-12-14T01:51:27.901062Z"},"trusted":true},"outputs":[],"source":["# 定义训练函数(参数为网络模型，训练加载器，测试加载器，批量样本数，优化器，运算设备，训练回合数)\n","def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n","    net = net.to(device)  # 网络模型搬移至指定的设备上\n","    print(\"training on \", device)  # 查看当前训练所用的设备\n","    loss = torch.nn.CrossEntropyLoss()  # 损失函数loss使用交叉熵损失函数\n","    batch_count = 0  # 批量计数器设为0\n","    for epoch in range(num_epochs):  # 循环训练回合，每回合会以批量为单位训练完整个训练集，一共训练num_epochs个回合\n","        # 每一训练回合初始化累计训练损失函数为0.0，累计训练正确样本数为0.0，训练样本总数为0，start为开始计时的时间点\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:  # 循环每次取一批量的图像与标签\n","            X = X.to(device)  # 将图像搬移至指定设备上\n","            y = y.to(device)  # 将标签搬移至指定设备上\n","            y_hat = net(X)  # 将批量图像数据X输入网络模型net，得到输出批量预测数据y_hat\n","            l = loss(y_hat, y)  # 计算批量预测标签y_hat与批量真实标签y之间的损失函数l\n","            optimizer.zero_grad()  # 优化器的梯度清零\n","            l.backward()  # 对批量损失函数l进行反向传播计算梯度\n","            optimizer.step()  # 优化器的梯度进行更新，训练所得参数也更新\n","            train_l_sum += l.cpu().item()  # 将本批量损失函数l加至训练损失函数累计train_l_sum中\n","            # 将本批量预测正确的样本数加至累计预测正确样本数train_acc_sum中\n","            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n","            n += y.shape[0]  # 将本批量训练的样本数，加至训练样本总数\n","            batch_count += 1  # 批量计数器加1\n","        # 对本回合训练所得网络模型参数，以批量为单位，测试全集去验证，得到测试集预测准确度\n","        test_acc = evaluate_accuracy(test_iter, net)\n","        # 打印回合数，每回合平均损失函数，每回合的训练集准确度，每回合的测试集准确度，每回合用时\n","        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n","    test_acc = evaluate_accuracy(test_iter, net)\n","    print('Accuracy of the network on the 10000 test images: %.3f %%' % (100*test_acc))\n","    classify(net,device)\n"]},{"cell_type":"code","execution_count":112,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T01:51:27.915667Z","iopub.status.busy":"2023-12-14T01:51:27.915398Z","iopub.status.idle":"2023-12-14T02:00:32.089038Z","shell.execute_reply":"2023-12-14T02:00:32.087620Z","shell.execute_reply.started":"2023-12-14T01:51:27.915645Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["training on  cuda\n","epoch 1, loss 1.7295, train acc 0.373, test acc 0.508, time 26.9 sec\n","epoch 2, loss 0.5758, train acc 0.588, test acc 0.556, time 26.9 sec\n","epoch 3, loss 0.2874, train acc 0.694, test acc 0.729, time 26.9 sec\n","epoch 4, loss 0.1684, train acc 0.763, test acc 0.766, time 27.0 sec\n","epoch 5, loss 0.1077, train acc 0.811, test acc 0.747, time 26.9 sec\n","epoch 6, loss 0.0749, train acc 0.844, test acc 0.806, time 27.0 sec\n","epoch 7, loss 0.0543, train acc 0.868, test acc 0.822, time 27.0 sec\n","epoch 8, loss 0.0406, train acc 0.888, test acc 0.845, time 26.9 sec\n","epoch 9, loss 0.0307, train acc 0.903, test acc 0.841, time 27.0 sec\n","epoch 10, loss 0.0228, train acc 0.922, test acc 0.827, time 26.9 sec\n","epoch 11, loss 0.0182, train acc 0.932, test acc 0.854, time 26.9 sec\n","epoch 12, loss 0.0141, train acc 0.942, test acc 0.838, time 27.0 sec\n","epoch 13, loss 0.0111, train acc 0.951, test acc 0.855, time 26.9 sec\n","epoch 14, loss 0.0089, train acc 0.957, test acc 0.846, time 26.9 sec\n","epoch 15, loss 0.0072, train acc 0.963, test acc 0.851, time 27.0 sec\n","epoch 16, loss 0.0063, train acc 0.965, test acc 0.855, time 27.0 sec\n","epoch 17, loss 0.0053, train acc 0.970, test acc 0.856, time 26.9 sec\n","epoch 18, loss 0.0041, train acc 0.975, test acc 0.851, time 26.9 sec\n","epoch 19, loss 0.0040, train acc 0.974, test acc 0.848, time 26.9 sec\n","epoch 20, loss 0.0034, train acc 0.976, test acc 0.852, time 27.0 sec\n","Accuracy of the network on the 10000 test images: 85.210 %\n","Accuracy of plane : 92 %\n","Accuracy of   car : 95 %\n","Accuracy of  bird : 76 %\n","Accuracy of   cat : 72 %\n","Accuracy of  deer : 81 %\n","Accuracy of   dog : 74 %\n","Accuracy of  frog : 90 %\n","Accuracy of horse : 92 %\n","Accuracy of  ship : 90 %\n","Accuracy of truck : 95 %\n"]}],"source":["net = ResNet(BasicBlock, [2, 2, 2, 2])\n","#定义一个训练批量的样本数\n","batch_size=128\n","#构建可迭代的数据装载器(参数为数据集，一个批量的样本数，是否乱序，工作线程数)\n","train_iter = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","test_iter = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n","#多GPU训练及优化\n","if device == 'cuda':\n","#对象net可进行多GPU并行处理\n","    net = torch.nn.DataParallel(net)\n","#cudnn是英伟达为深度神经网络开发的GPU加速库,让内置的cudnn的auto-tuner自动寻找最适合当前配置的高效算法,来达到优化运行效率的问题。\n","    cudnn.benchmark = True\n","#设置学习率lr，训练回合数num_epochs\n","lr, num_epochs = 0.01, Epochs\n","#设置优化器为Adam优化器，参数为网络模型的参数和学习率\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","#开始训练模型，参数为网络模型，训练加载器，测试加载器，批量大小，优化器，运算设备，训练回合数\n","train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n","resnet18=net\n"]},{"cell_type":"markdown","metadata":{},"source":["# VGG加深网络"]},{"cell_type":"code","execution_count":113,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:00:32.091828Z","iopub.status.busy":"2023-12-14T02:00:32.091412Z","iopub.status.idle":"2023-12-14T02:00:32.132856Z","shell.execute_reply":"2023-12-14T02:00:32.131855Z","shell.execute_reply.started":"2023-12-14T02:00:32.091782Z"},"trusted":true},"outputs":[],"source":["class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n","        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu1 = nn.ReLU()\n","\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.pool2 = nn.MaxPool2d(2, 2, padding=1)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.relu2 = nn.ReLU()\n","\n","        self.conv5 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.conv7 = nn.Conv2d(128, 128, 1, padding=1)\n","        self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.relu3 = nn.ReLU()\n","\n","        self.conv8 = nn.Conv2d(128, 256, 3, padding=1)\n","        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)\n","        self.conv10 = nn.Conv2d(256, 256, 1, padding=1)\n","        self.pool4 = nn.MaxPool2d(2, 2, padding=1)\n","        self.bn4 = nn.BatchNorm2d(256)\n","        self.relu4 = nn.ReLU()\n","\n","        self.conv11 = nn.Conv2d(256, 512, 3, padding=1)\n","        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n","        self.conv13 = nn.Conv2d(512, 512, 1, padding=1)\n","        self.pool5 = nn.MaxPool2d(2, 2, padding=1)\n","        self.bn5 = nn.BatchNorm2d(512)\n","        self.relu5 = nn.ReLU()\n","\n","        self.fc14 = nn.Linear(512 * 4 * 4, 1024)\n","        self.drop = nn.Dropout()\n","        self.fc15 = nn.Linear(1024, 1024)\n","        self.fc16 = nn.Linear(1024, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.pool1(x)\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.pool2(x)\n","        x = self.bn2(x)\n","        x = self.relu2(x)\n","\n","        x = self.conv5(x)\n","        x = self.conv6(x)\n","        x = self.conv7(x)\n","        x = self.pool3(x)\n","        x = self.bn3(x)\n","        x = self.relu3(x)\n","\n","        x = self.conv8(x)\n","        x = self.conv9(x)\n","        x = self.conv10(x)\n","        x = self.pool4(x)\n","        x = self.bn4(x)\n","        x = self.relu4(x)\n","\n","        x = self.conv11(x)\n","        x = self.conv12(x)\n","        x = self.conv13(x)\n","        x = self.pool5(x)\n","        x = self.bn5(x)\n","        x = self.relu5(x)\n","        # print(\" x shape \",x.size())\n","        x = x.view(-1, 512 * 4 * 4)\n","        x = F.relu(self.fc14(x))\n","        x = self.drop(x)\n","        x = F.relu(self.fc15(x))\n","        x = self.drop(x)\n","        x = self.fc16(x)\n","\n","        return x\n","\n","    def train_sgd(self, device):\n","\n","        optimizer = optim.SGD(self.parameters(), lr=0.01)\n","        path = 'weights.tar'\n","        initepoch = 0\n","\n","        if os.path.exists(path) is not True:\n","            loss = nn.CrossEntropyLoss()\n","\n","\n","        else:\n","            checkpoint = torch.load(path)\n","            self.load_state_dict(checkpoint['model_state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            initepoch = checkpoint['epoch']\n","            loss = checkpoint['loss']\n","\n","        for epoch in range(initepoch, Epochs):  # loop over the dataset multiple times\n","            timestart = time.time()\n","\n","            running_loss = 0.0\n","            total = 0\n","            correct = 0\n","            for i, data in enumerate(trainloader, 0):\n","                # get the inputs\n","                inputs, labels = data\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                outputs = self(inputs)\n","                l = loss(outputs, labels)\n","                l.backward()\n","                optimizer.step()\n","\n","                running_loss += l.item()\n","\n","                if i % 500 == 499:\n","                    print('[%d, %5d] loss: %.4f' %\n","                          (epoch, i, running_loss / 500))\n","                    running_loss = 0.0\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    total += labels.size(0)\n","                    correct += (predicted == labels).sum().item()\n","                    print('Accuracy of the network on the %d tran images: %.3f %%' % (total,\n","                                                                                      100.0 * correct / total))\n","                    total = 0\n","                    correct = 0\n","                    torch.save({'epoch': epoch,\n","                                'model_state_dict': net.state_dict(),\n","                                'optimizer_state_dict': optimizer.state_dict(),\n","                                'loss': loss\n","                                }, path)\n","            \n","            print('epoch %d cost %3f sec' % (epoch, time.time() - timestart))\n","\n","        print('Finished Training')\n","\n","    def test(self, device):\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for data in testloader:\n","                images, labels = data\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = self(images)\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        print('Accuracy of the network on the 10000 test images: %.3f %%' % (100.0 * correct / total))\n","\n","    def classify(self, device):\n","        class_correct = list(0. for i in range(10))\n","        class_total = list(0. for i in range(10))\n","        for data in testloader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = self(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            c = (predicted == labels).squeeze()\n","            for i in range(4):\n","                label = labels[i]\n","                class_correct[label] += c[i]\n","                class_total[label] += 1\n","\n","        for i in range(10):\n","            print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n"]},{"cell_type":"code","execution_count":114,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:00:32.134774Z","iopub.status.busy":"2023-12-14T02:00:32.134282Z","iopub.status.idle":"2023-12-14T02:01:37.324252Z","shell.execute_reply":"2023-12-14T02:01:37.322968Z","shell.execute_reply.started":"2023-12-14T02:00:32.134747Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[16,   499] loss: 0.1762\n","Accuracy of the network on the 100 tran images: 94.000 %\n","epoch 16 cost 15.114440 sec\n","[17,   499] loss: 0.1626\n","Accuracy of the network on the 100 tran images: 93.000 %\n","epoch 17 cost 15.087104 sec\n","[18,   499] loss: 0.1518\n","Accuracy of the network on the 100 tran images: 91.000 %\n","epoch 18 cost 15.103201 sec\n","[19,   499] loss: 0.1336\n","Accuracy of the network on the 100 tran images: 95.000 %\n","epoch 19 cost 15.086041 sec\n","Finished Training\n","Accuracy of the network on the 10000 test images: 83.220 %\n","Accuracy of plane : 84 %\n","Accuracy of   car : 91 %\n","Accuracy of  bird : 82 %\n","Accuracy of   cat : 66 %\n","Accuracy of  deer : 75 %\n","Accuracy of   dog : 62 %\n","Accuracy of  frog : 85 %\n","Accuracy of horse : 80 %\n","Accuracy of  ship : 88 %\n","Accuracy of truck : 87 %\n"]}],"source":["if __name__ == '__main__':\n","    net = Net()\n","    net = net.to(device)\n","    net.train_sgd(device)\n","    net.test(device)\n","    net.classify(device)"]},{"cell_type":"code","execution_count":115,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:01:37.326786Z","iopub.status.busy":"2023-12-14T02:01:37.326351Z","iopub.status.idle":"2023-12-14T02:01:47.392339Z","shell.execute_reply":"2023-12-14T02:01:47.391193Z","shell.execute_reply.started":"2023-12-14T02:01:37.326742Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: torch.Size([50000, 3, 32, 32])\n","y_train shape: torch.Size([50000])\n"]}],"source":["# 初始化空列表用于存储所有数据\n","X_train, y_train = [], []\n","\n","# 遍历所有训练集数据\n","for batch_X, batch_y in trainloader:\n","    X_train.append(batch_X)\n","    y_train.append(batch_y)\n","\n","# 将列表中的 Tensor 拼接成一个整体\n","X_train = torch.cat(X_train, dim=0)\n","y_train = torch.cat(y_train, dim=0)\n","\n","# 打印样本形状\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n"]},{"cell_type":"code","execution_count":116,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:01:47.394506Z","iopub.status.busy":"2023-12-14T02:01:47.394169Z","iopub.status.idle":"2023-12-14T02:01:49.457576Z","shell.execute_reply":"2023-12-14T02:01:49.456236Z","shell.execute_reply.started":"2023-12-14T02:01:47.394472Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X_test shape: torch.Size([10000, 3, 32, 32])\n","y_test shape: torch.Size([10000])\n"]}],"source":["# 同样方式处理测试集\n","X_test, y_test = [], []\n","\n","for batch_X, batch_y in testloader:\n","    X_test.append(batch_X)\n","    y_test.append(batch_y)\n","\n","X_test = torch.cat(X_test, dim=0)\n","y_test = torch.cat(y_test, dim=0)\n","\n","# 打印样本形状\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)"]},{"cell_type":"code","execution_count":117,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:01:49.459825Z","iopub.status.busy":"2023-12-14T02:01:49.459415Z","iopub.status.idle":"2023-12-14T02:01:49.695295Z","shell.execute_reply":"2023-12-14T02:01:49.694348Z","shell.execute_reply.started":"2023-12-14T02:01:49.459782Z"},"scrolled":true,"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1500x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","def plot_sample(X, y, index):\n","    plt.figure(figsize=(15, 2))\n","    img = X[index].permute(1, 2, 0)  # 使用permute替代transpose\n","    plt.imshow(img)\n","    plt.xlabel(f\"Class: {classes[y[index].item()]}\")\n","\n","# 调用这个函数\n","plot_sample(X_train, y_train, 10)\n","\n"]},{"cell_type":"code","execution_count":118,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:01:49.697402Z","iopub.status.busy":"2023-12-14T02:01:49.696737Z","iopub.status.idle":"2023-12-14T02:01:49.910803Z","shell.execute_reply":"2023-12-14T02:01:49.909823Z","shell.execute_reply.started":"2023-12-14T02:01:49.697366Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1500x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plot_sample(X_train, y_train, 1)"]},{"cell_type":"markdown","metadata":{},"source":["# ANN"]},{"cell_type":"code","execution_count":119,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:01:49.913115Z","iopub.status.busy":"2023-12-14T02:01:49.912807Z","iopub.status.idle":"2023-12-14T02:03:13.893116Z","shell.execute_reply":"2023-12-14T02:03:13.892110Z","shell.execute_reply.started":"2023-12-14T02:01:49.913088Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.8733 - accuracy: 0.3467\n","Epoch 2/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7888 - accuracy: 0.3813\n","Epoch 3/20\n","1563/1563 [==============================] - 3s 2ms/step - loss: 1.7646 - accuracy: 0.3924\n","Epoch 4/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7489 - accuracy: 0.3983\n","Epoch 5/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7399 - accuracy: 0.4005\n","Epoch 6/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7326 - accuracy: 0.4052\n","Epoch 7/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7254 - accuracy: 0.4076\n","Epoch 8/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7209 - accuracy: 0.4066\n","Epoch 9/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7164 - accuracy: 0.4112\n","Epoch 10/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7125 - accuracy: 0.4132\n","Epoch 11/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7108 - accuracy: 0.4143\n","Epoch 12/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7065 - accuracy: 0.4164\n","Epoch 13/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7036 - accuracy: 0.4157\n","Epoch 14/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.7015 - accuracy: 0.4187\n","Epoch 15/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.6978 - accuracy: 0.4169\n","Epoch 16/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.6964 - accuracy: 0.4182\n","Epoch 17/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.6934 - accuracy: 0.4207\n","Epoch 18/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.6916 - accuracy: 0.4221\n","Epoch 19/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.6909 - accuracy: 0.4202\n","Epoch 20/20\n","1563/1563 [==============================] - 4s 2ms/step - loss: 1.6880 - accuracy: 0.4214\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x7cf4be8befe0>"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["from keras import models, layers\n","\n","# 将 PyTorch 张量转换为 NumPy 数组\n","X_train_np = X_train.permute(0, 2, 3, 1).numpy()  # 调整维度顺序\n","y_train_np = y_train.numpy()\n","\n","# 创建 Keras 模型\n","ann = models.Sequential([\n","    layers.Input(shape=(32, 32, 3)),  # 直接设置输入形状\n","    layers.Flatten(),\n","    # ... 其他层 ...\n","    layers.Dense(10, activation='softmax')    \n","])\n","\n","# 编译模型\n","ann.compile(optimizer='SGD',\n","            loss='sparse_categorical_crossentropy',\n","            metrics=['accuracy'])\n","\n","# 在 NumPy 数组上训练模型\n","ann.fit(X_train_np, y_train_np, epochs=Epochs)\n","\n"]},{"cell_type":"code","execution_count":120,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:03:13.894726Z","iopub.status.busy":"2023-12-14T02:03:13.894429Z","iopub.status.idle":"2023-12-14T02:03:14.929917Z","shell.execute_reply":"2023-12-14T02:03:14.929045Z","shell.execute_reply.started":"2023-12-14T02:03:13.894701Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 0s 1ms/step\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.44      0.47      0.46      1000\n","           1       0.43      0.40      0.41      1000\n","           2       0.29      0.29      0.29      1000\n","           3       0.29      0.23      0.26      1000\n","           4       0.32      0.21      0.25      1000\n","           5       0.31      0.33      0.32      1000\n","           6       0.36      0.51      0.42      1000\n","           7       0.40      0.48      0.44      1000\n","           8       0.54      0.46      0.49      1000\n","           9       0.43      0.46      0.44      1000\n","\n","    accuracy                           0.38     10000\n","   macro avg       0.38      0.38      0.38     10000\n","weighted avg       0.38      0.38      0.38     10000\n","\n"]}],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# 调整 PyTorch 测试数据的维度顺序\n","X_test_permuted = X_test.permute(0, 2, 3, 1)\n","\n","# 将 PyTorch 测试数据转换为 NumPy 数组\n","X_test_np = X_test_permuted.numpy()\n","\n","# 使用 Keras 模型进行预测\n","y_pred = ann.predict(X_test_np)\n","\n","# 获取预测类别\n","y_pred_classes = [np.argmax(element) for element in y_pred]\n","\n","# 打印分类报告等信息\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred_classes))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# CNN"]},{"cell_type":"code","execution_count":121,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:03:14.931523Z","iopub.status.busy":"2023-12-14T02:03:14.931146Z","iopub.status.idle":"2023-12-14T02:03:14.949418Z","shell.execute_reply":"2023-12-14T02:03:14.948607Z","shell.execute_reply.started":"2023-12-14T02:03:14.931493Z"},"trusted":true},"outputs":[],"source":["cnn = models.Sequential([\n","    layers.Reshape((32, 32, 3)), \n","    layers.MaxPooling2D((2, 2)),\n","    \n","    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    \n","    layers.Flatten(),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(10, activation='softmax')\n","])"]},{"cell_type":"code","execution_count":122,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:03:14.950830Z","iopub.status.busy":"2023-12-14T02:03:14.950489Z","iopub.status.idle":"2023-12-14T02:03:14.964864Z","shell.execute_reply":"2023-12-14T02:03:14.963902Z","shell.execute_reply.started":"2023-12-14T02:03:14.950795Z"},"trusted":true},"outputs":[],"source":["cnn.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":123,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:03:14.966694Z","iopub.status.busy":"2023-12-14T02:03:14.966165Z","iopub.status.idle":"2023-12-14T02:04:51.617184Z","shell.execute_reply":"2023-12-14T02:04:51.616161Z","shell.execute_reply.started":"2023-12-14T02:03:14.966659Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","1563/1563 [==============================] - 6s 3ms/step - loss: 1.4654 - accuracy: 0.4828\n","Epoch 2/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 1.1995 - accuracy: 0.5814\n","Epoch 3/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 1.1068 - accuracy: 0.6141\n","Epoch 4/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 1.0381 - accuracy: 0.6373\n","Epoch 5/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.9827 - accuracy: 0.6571\n","Epoch 6/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.9390 - accuracy: 0.6715\n","Epoch 7/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.8984 - accuracy: 0.6853\n","Epoch 8/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.8610 - accuracy: 0.6992\n","Epoch 9/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.8242 - accuracy: 0.7101\n","Epoch 10/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.7894 - accuracy: 0.7221\n","Epoch 11/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.7592 - accuracy: 0.7323\n","Epoch 12/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.7276 - accuracy: 0.7434\n","Epoch 13/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.6959 - accuracy: 0.7556\n","Epoch 14/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.6721 - accuracy: 0.7618\n","Epoch 15/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.6425 - accuracy: 0.7727\n","Epoch 16/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.6177 - accuracy: 0.7826\n","Epoch 17/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.5896 - accuracy: 0.7922\n","Epoch 18/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.5692 - accuracy: 0.7984\n","Epoch 19/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.5429 - accuracy: 0.8070\n","Epoch 20/20\n","1563/1563 [==============================] - 5s 3ms/step - loss: 0.5189 - accuracy: 0.8152\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x7cf4be844d90>"]},"execution_count":123,"metadata":{},"output_type":"execute_result"}],"source":["cnn.fit(X_train_np, y_train_np, epochs=Epochs)"]},{"cell_type":"code","execution_count":124,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T02:04:51.618878Z","iopub.status.busy":"2023-12-14T02:04:51.618579Z","iopub.status.idle":"2023-12-14T02:04:58.762282Z","shell.execute_reply":"2023-12-14T02:04:58.761064Z","shell.execute_reply.started":"2023-12-14T02:04:51.618851Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ANN:\n","313/313 [==============================] - 1s 2ms/step - loss: 1.7963 - accuracy: 0.3832\n","CNN:\n","313/313 [==============================] - 1s 2ms/step - loss: 1.3511 - accuracy: 0.6285\n","VGG:\n","Accuracy of the network on the 10000 test images: 82.980 %\n","ResNet:\n","Accuracy of the network on the 10000 test images: 85.890 %\n"]}],"source":["y_test_np = y_test.detach().numpy()\n","print(\"ANN:\")\n","ann.evaluate(X_test_np,y_test_np)\n","print(\"CNN:\")\n","cnn.evaluate(X_test_np,y_test_np)\n","print(\"VGG:\")\n","net.test(device)\n","print(\"ResNet:\")\n","test_acc = evaluate_accuracy(test_iter, resnet18)\n","print('Accuracy of the network on the 10000 test images: %.3f %%' % (100*test_acc))"]},{"cell_type":"markdown","metadata":{},"source":["可以看出，在训练了20轮后，ANN的精度在38%左右，CNN的精度在63%左右，VGG加深网络的精度在82.98%，Resnet18残差网络的精度在85.89%，残差网络的识别效果最好"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4079957,"sourceId":7082158,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
