{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:blue' align='center'>Small Image Classification Using Convolutional Neural Network (CNN)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](small_images.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10数据集是一个用于监督学习训练的数据集，由60000个样本组成，每个样本都是一张32*32像素的RGB图像，共有10个类别，分别是飞机（airplane）、汽车（automobile）、鸟（bird）、猫（cat）、鹿（deer）、狗（dog）、青蛙（frog）、马（horse）、船（ship）和卡车（truck）。\n",
    "以下是CIFAR-10数据集的出处链接：\n",
    "[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see there are 50000 training images and 1000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train is a 2D array, for our classification having 1D array is good enough. so we will convert this to now 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4, 1], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some images to see what they are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, index):\n",
    "    plt.figure(figsize = (15,2))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(classes[y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_train, y_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and each value in the channel can range from 0 to 255. Hence to normalize in 0-->1 range, we need to divide it by 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:purple\">Normalizing the training data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:purple\">Build simple artificial neural network for image classification</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1563/1563 [==============================] - 61s 38ms/step - loss: 1.8138 - accuracy: 0.3559\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.6245 - accuracy: 0.4276\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 1.5430 - accuracy: 0.4547\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 1.4835 - accuracy: 0.4791\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 62s 39ms/step - loss: 1.4344 - accuracy: 0.4946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x201cf5b5a30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = models.Sequential([\n",
    "        layers.Flatten(input_shape=(32,32,3)),\n",
    "        layers.Dense(3000, activation='relu'),\n",
    "        layers.Dense(1000, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')    \n",
    "    ])\n",
    "\n",
    "ann.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can see that at the end of 5 epochs, accuracy is at around 49%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.39      0.48      1000\n",
      "           1       0.56      0.66      0.61      1000\n",
      "           2       0.33      0.41      0.36      1000\n",
      "           3       0.28      0.39      0.32      1000\n",
      "           4       0.56      0.17      0.27      1000\n",
      "           5       0.35      0.42      0.38      1000\n",
      "           6       0.41      0.69      0.51      1000\n",
      "           7       0.59      0.53      0.56      1000\n",
      "           8       0.59      0.65      0.62      1000\n",
      "           9       0.73      0.26      0.38      1000\n",
      "\n",
      "    accuracy                           0.46     10000\n",
      "   macro avg       0.50      0.46      0.45     10000\n",
      "weighted avg       0.50      0.46      0.45     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import numpy as np\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:purple\">Now let us build a convolutional neural network to train our images</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 1.4383 - accuracy: 0.4822\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.0887 - accuracy: 0.6180\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.9566 - accuracy: 0.6654\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.8719 - accuracy: 0.6981\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8026 - accuracy: 0.7214\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7429 - accuracy: 0.7408\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6884 - accuracy: 0.7596\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.6344 - accuracy: 0.7777\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.5853 - accuracy: 0.7949\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.5419 - accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x201c6abc460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With CNN, at the end 5 epochs, accuracy was at around 70% which is a significant improvement over ANN. CNN's are best for image classification and gives superb accuracy. Also computation is much less compared to simple ANN as maxpooling reduces the image dimensions while still preserving the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.9583 - accuracy: 0.6983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9582706093788147, 0.6983000040054321]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.47434203e-03, 1.50264779e-04, 2.16622348e-03, 8.01496267e-01,\n",
       "        3.97145329e-03, 9.68173742e-02, 7.39848148e-03, 1.40058026e-02,\n",
       "        6.55730590e-02, 2.94682221e-03],\n",
       "       [2.90070282e-04, 4.18267474e-02, 2.91242657e-07, 4.16082827e-07,\n",
       "        2.96938012e-08, 3.56598084e-09, 4.76184539e-07, 2.31252031e-08,\n",
       "        9.55340624e-01, 2.54131691e-03],\n",
       "       [1.51937315e-02, 3.46157961e-02, 4.36219480e-03, 2.02598330e-02,\n",
       "        9.13610449e-04, 5.72325953e-04, 2.54534394e-03, 8.02564144e-04,\n",
       "        8.79473269e-01, 4.12612930e-02],\n",
       "       [9.48755741e-01, 2.01395698e-04, 1.39896962e-04, 4.13682923e-04,\n",
       "        4.26460261e-04, 5.95104029e-06, 2.77967683e-06, 8.33031954e-05,\n",
       "        4.96490300e-02, 3.21566535e-04],\n",
       "       [1.00227708e-05, 1.38728530e-04, 1.60975277e-01, 1.91182848e-02,\n",
       "        4.11843449e-01, 2.93982797e-03, 4.04807597e-01, 1.37670247e-06,\n",
       "        1.64629295e-04, 7.66728419e-07]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 8, 0, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, 0, 6], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_test, y_test,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deer'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[y_classes[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deer'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[y_classes[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10_vgg\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:25<00:00, 6599119.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar10_vgg\\cifar-10-python.tar.gz to ./cifar10_vgg\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\torch\\nn\\functional.py:1345: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,   499] loss: 1.6531\n",
      "Accuracy of the network on the 100 tran images: 52.000 %\n",
      "epoch 0 cost 369.191658 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\python\\综合任务\\cnn_cifar10_dataset.ipynb 单元格 38\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=212'>213</a>\u001b[0m net \u001b[39m=\u001b[39m Net()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=213'>214</a>\u001b[0m net \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=214'>215</a>\u001b[0m net\u001b[39m.\u001b[39;49mtrain_sgd(device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=215'>216</a>\u001b[0m net\u001b[39m.\u001b[39mtest(device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=216'>217</a>\u001b[0m net\u001b[39m.\u001b[39mclassify(device)\n",
      "\u001b[1;32md:\\Desktop\\python\\综合任务\\cnn_cifar10_dataset.ipynb 单元格 38\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(inputs)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m l \u001b[39m=\u001b[39m loss(outputs, labels)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m l\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32md:\\Desktop\\python\\综合任务\\cnn_cifar10_dataset.ipynb 单元格 38\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/python/%E7%BB%BC%E5%90%88%E4%BB%BB%E5%8A%A1/cnn_cifar10_dataset.ipynb#X55sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n",
      "File \u001b[1;32mc:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\shan\\.conda\\envs\\PytorchCpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomGrayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform1 = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10_vgg', train=True, download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10_vgg', train=False, download=False, transform=transform1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=50, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 128, 1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv8 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(256, 256, 1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv11 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc14 = nn.Linear(512 * 4 * 4, 1024)\n",
    "        self.drop1 = nn.Dropout2d()\n",
    "        self.fc15 = nn.Linear(1024, 1024)\n",
    "        self.drop2 = nn.Dropout2d()\n",
    "        self.fc16 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.pool5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        # print(\" x shape \",x.size())\n",
    "        x = x.view(-1, 512 * 4 * 4)\n",
    "        x = F.relu(self.fc14(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc15(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc16(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def train_sgd(self, device):\n",
    "\n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.01)\n",
    "        path = 'weights.tar'\n",
    "        initepoch = 0\n",
    "\n",
    "        if os.path.exists(path) is not True:\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "        else:\n",
    "            checkpoint = torch.load(path)\n",
    "            self.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            initepoch = checkpoint['epoch']\n",
    "            loss = checkpoint['loss']\n",
    "\n",
    "        for epoch in range(initepoch, 20):  # loop over the dataset multiple times\n",
    "            timestart = time.time()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self(inputs)\n",
    "                l = loss(outputs, labels)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += l.item()\n",
    "\n",
    "                if i % 500 == 499:\n",
    "                    print('[%d, %5d] loss: %.4f' %\n",
    "                          (epoch, i, running_loss / 500))\n",
    "                    running_loss = 0.0\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    print('Accuracy of the network on the %d tran images: %.3f %%' % (total,\n",
    "                                                                                      100.0 * correct / total))\n",
    "                    total = 0\n",
    "                    correct = 0\n",
    "                    torch.save({'epoch': epoch,\n",
    "                                'model_state_dict': net.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'loss': loss\n",
    "                                }, path)\n",
    "\n",
    "            print('epoch %d cost %3f sec' % (epoch, time.time() - timestart))\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "    def test(self, device):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the 10000 test images: %.3f %%' % (100.0 * correct / total))\n",
    "\n",
    "    def classify(self, device):\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = self(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i]\n",
    "                class_total[label] += 1\n",
    "\n",
    "        for i in range(10):\n",
    "            print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = Net()\n",
    "    net = net.to(device)\n",
    "    net.train_sgd(device)\n",
    "    net.test(device)\n",
    "    net.classify(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:purple'>Exercise</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CNN to do handwritten digits classification using MNIST dataset. You can use this notebook as a reference:\n",
    "https://github.com/codebasics/deep-learning-keras-tf-tutorial/blob/main/1_digits_recognition/digits_recognition_neural_network.ipynb\n",
    "\n",
    "Above we used ANN for digits classification. You need to modify this code to use CNN instead. Check how accuracy improves fast with CNN and figure out how CNN can be a better choice for doing image classification compared to ANN. Once you have worked on this problem on your own, you can check my solution by clicking on this link: [Solution](https://github.com/codebasics/deep-learning-keras-tf-tutorial/blob/main/16_cnn_cifar10_small_image_classification/cnn_mnist_exercise_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
